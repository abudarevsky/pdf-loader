(GNNs) to build a high ﬁdelity model of their problem domain which can drive the models that automate
their business processes under a Software 2.0 model as deﬁned by Andrej Karpathy and Ratner, Hancock
and Ré.
Heterogeneous knowledge graphs oﬀer a rich domain in which to model your market and its problems.
When combined with heterogenous graphlets and motifs, motif search against null models and Motif Graph
Neural Networks, they oﬀer an eﬃcient way to create automated solutions using representation learning
that builds on top of the domain expertise previously expressed by an organization in the form of graph
queries. These distributed representations of the problem domain of a market are the core assets that drive
FAANG companies… and is causing other enterprises to follow them in transforming their companies to be
model ﬁrst, rather than code ﬁrst.
Without a factory to make the workﬂow more eﬃcient, innovative enterprises spend eight ﬁgure budgets on
knowledge graph projects that fail to provide a return on investment. If a property graph factory could make
the process above 25%, 50% or 75% faster it would create an enormous amount of value for its users.
Spending $5M instead of $10M to achieve an improved outcome constitutes enterprise value.
The graph database and knowledge graph markets have long been frustrated by the failure of the semantic
web and many enterprise knowledge graph factories are closed silos based on legacy technology. I believe
the market will explode once the Python open data stack is easy to apply to model a problem using graph
machine learning. It is the mission of Graphlet AI to build a Property Graph Factory that brings network
science and graph machine learning into the operations of enterprises across the globe.

## PROBLEM DEFINITION
The knowledge graph and graph database markets have long asked themselves: why aren’t we larger? The
vision of the semantic web was that many datasets could be cross-referenced between independent graph
databases to map all knowledge on the web from myriad disparate datasets into one or more authoritative
ontologies which could be accessed by writing SPARQL queries to hop from one knowledge graph to
another. The reality of dirty data made this vision impossible, as Cory Doctorow outlined in his essay
Metacrap.
1
